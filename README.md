# Proyecto de ETL y Data Warehouse para GestiÃ³n Comercial ğŸ“Š

Este proyecto implementa un proceso completo de **ETL (ExtracciÃ³n, TransformaciÃ³n y Carga)** para centralizar, limpiar y estructurar los datos comerciales de tres empresas distintas (dos distribuidoras y una fÃ¡brica). El objetivo final es crear un **Data Warehouse** robusto en PostgreSQL que sirva como una Ãºnica fuente de verdad para el anÃ¡lisis de negocio, la generaciÃ³n de informes y el cÃ¡lculo de comisiones.

---
## Arquitectura de la SoluciÃ³n ğŸ—ï¸

La soluciÃ³n estÃ¡ diseÃ±ada siguiendo las mejores prÃ¡cticas de la ingenierÃ­a de datos:

1.  **ExtracciÃ³n:** Scripts de Python se conectan a una API de TNS para extraer datos crudos de productos y clientes.
2.  **TransformaciÃ³n:** Los datos extraÃ­dos pasan por una capa de limpieza, estandarizaciÃ³n y enriquecimiento. Se aplican reglas de negocio para corregir inconsistencias.
3.  **Carga:** Los datos limpios se cargan en una base de datos PostgreSQL, diseÃ±ada con un **Esquema en Estrella**.
4.  **GestiÃ³n y AuditorÃ­a:** Un conjunto de scripts de apoyo permite la gestiÃ³n manual de clasificaciones de negocio y genera reportes para mantener la calidad de los datos.

---
## Conceptos Clave de Modelado de Datos ğŸ’¡

Este proyecto utiliza varios conceptos fundamentales para asegurar que la informaciÃ³n sea Ã­ntegra y eficiente.

* **Esquema en Estrella (Star Schema):** Separa los datos en **Tablas de Hechos** (mÃ©tricas, nÃºmeros) y **Tablas de DimensiÃ³n** (contexto descriptivo).
* **Dimensiones de Lenta VariaciÃ³n (SCD) Tipo 2:** En lugar de sobrescribir datos que cambian con el tiempo, se crean nuevos registros con un perÃ­odo de validez. Esto nos permite mantener un historial completo (ej. para clasificaciones de clientes o roles de vendedores).
* **Llaves Sustitutas vs. de Negocio:** Usamos IDs numÃ©ricos internos (`id_producto`) para la eficiencia de la base de datos (Llave Sustituta) y mantenemos los cÃ³digos del mundo real (`codigo_erp`) para el anÃ¡lisis y la lÃ³gica de negocio (Llave de Negocio).

---
## Estructura del Repositorio ğŸ“‚

```
proyectos-gestion-comercial/
â”‚
â”œâ”€â”€ .env                  # (Archivo local) Credenciales y secretos.
â”œâ”€â”€ config.py             # ConfiguraciÃ³n central del proyecto.
â”œâ”€â”€ db_utils.py           # Funciones reutilizables para la base de datos.
â”œâ”€â”€ requirements.txt      # Dependencias de Python.
â”œâ”€â”€ README.md             # Este archivo.
â”‚
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ gestion_comercial_schema.sql # Blueprint completo de la base de datos.
â”‚
â”œâ”€â”€ datos_entrada/        # Archivos CSV para la carga y gestiÃ³n manual.
â”‚
â”œâ”€â”€ informes_generados/   # Reportes automÃ¡ticos (cambios, pendientes, etc.).
â”‚
â”œâ”€â”€ 00_ETL_TNS/           # Scripts principales que extraen datos de la API.
â”‚   â”œâ”€â”€ cargar_productos_api.py
â”‚   â””â”€â”€ cargar_clientes_api.py
â”‚
â””â”€â”€ 01_MODELO_DATOS_Y_AUXILIARES/ # Scripts de apoyo, auditorÃ­a y sincronizaciÃ³n.
    â”œâ”€â”€ poblar_dimensiones_catalogo.py
    â”œâ”€â”€ auditoria_gestion_productos.py
    â”œâ”€â”€ sincronizar_gestion_productos.py
    â”œâ”€â”€ auditoria_gestion_clientes.py
    â”œâ”€â”€ sincronizar_maestro_clientes.py
    â””â”€â”€ sincronizar_clasificacion_clientes.py
```

---
## CÃ³mo Empezar (GuÃ­a de InstalaciÃ³n) ğŸš€

1.  **Clonar el Repositorio:** `git clone https://github.com/EdinsonHernandez92/proyectos_gestion_comercial.git`
2.  **Entorno Virtual:** `python -m venv venv` y actÃ­valo.
3.  **Archivo `.env`:** Crea el archivo `.env` en la raÃ­z y rellÃ©nalo con las credenciales de la base de datos y de la API.
4.  **Instalar Dependencias:** `pip install -r requirements.txt`
5.  **Crear Base de Datos:** Crea una base de datos en PostgreSQL llamada `gestion_comercial` y ejecuta el script `sql/gestion_comercial_schema.sql` para crear todas las tablas.

---
## Flujo de Trabajo de los Scripts ETL

El proyecto se divide en procesos automÃ¡ticos (para datos de la API) y procesos manuales (para tus datos de gestiÃ³n).

### 1. Proceso Diario (AutomÃ¡tico)
Estos scripts deben ejecutarse diariamente para mantener los datos maestros sincronizados.

* **`cargar_productos_api.py`:**
    * **MisiÃ³n:** Sincroniza la tabla `dim_productos` con la API. Inserta productos nuevos y actualiza los existentes.
    * **Reporte:** Genera un CSV en `informes_generados/` con los productos nuevos o modificados detectados en la API.
* **`cargar_clientes_api.py`:**
    * **MisiÃ³n:** Sincroniza la tabla `dim_clientes_empresa` con la API.
    * **Reporte:** Genera un CSV en `informes_generados/` con los clientes nuevos o modificados detectados en la API.

### 2. Proceso de GestiÃ³n (Manual)
Este es tu flujo de trabajo para clasificar los datos nuevos.

* **Paso A: AuditorÃ­a**
    * **`auditoria_gestion_productos.py`:** Encuentra los productos **activos y con ventas recientes** que aÃºn no has clasificado. Genera el archivo `productos_pendientes_por_clasificar.csv`.
    * **`auditoria_gestion_clientes.py`:** Encuentra los clientes **activos y con ventas recientes** que aÃºn no has aÃ±adido al maestro. Genera el archivo `clientes_pendientes_por_clasificar.csv`.
* **Paso B: Tu AcciÃ³n Manual**
    * Usando los reportes de la auditorÃ­a, actualizas tus archivos CSV maestros en la carpeta `datos_entrada/`.
* **Paso C: SincronizaciÃ³n**
    * **`sincronizar_gestion_productos.py`:** Lee tu `gestion_productos_aux.csv` y actualiza la tabla en la base de datos.
    * **`sincronizar_maestro_clientes.py`:** Lee tu `maestro_clientes.csv` y actualiza la tabla `maestro_clientes`.
    * **`sincronizar_clasificacion_clientes.py`:** Lee tu `dim_clientes_clasificacion_historia.csv` y actualiza las clasificaciones en la base de datos.